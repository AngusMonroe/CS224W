{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XuXWJLEm2UWS"
   },
   "source": [
    "# **CS224W - Colab 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8gzsP50bF6Gb"
   },
   "source": [
    "In this Colab, we will write a full pipeline for **learning node embeddings**.\n",
    "We will go through the following 3 steps.\n",
    "\n",
    "To start, we will load a classic graph in network science, the [Karate Club Network](https://en.wikipedia.org/wiki/Zachary%27s_karate_club). We will explore multiple graph statistics for that graph.\n",
    "\n",
    "We will then work together to transform the graph structure into a PyTorch tensor, so that we can perform machine learning over the graph.\n",
    "\n",
    "Finally, we will finish the first learning algorithm on graphs: a node embedding model. For simplicity, our model here is simpler than DeepWalk / node2vec algorithms taught in the lecture. But it's still rewarding and challenging, as we will write it from scratch via PyTorch.\n",
    "\n",
    "Now let's get started!\n",
    "\n",
    "**Note**: Make sure to **sequentially run all the cells**, so that the intermediate variables / packages will carry over to the next cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nwwq0nSdmsOL"
   },
   "source": [
    "# 1 Graph Basics\n",
    "To start, we will load a classic graph in network science, the [Karate Club Network](https://en.wikipedia.org/wiki/Zachary%27s_karate_club). We will explore multiple graph statistics for that graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FDkpByYYfSzb"
   },
   "source": [
    "## Setup\n",
    "We will heavily use NetworkX in this Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "id": "VWPkJjPAfVNW"
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VqUnYT5qUZYh"
   },
   "source": [
    "## Zachary's karate club network\n",
    "\n",
    "The [Karate Club Network](https://en.wikipedia.org/wiki/Zachary%27s_karate_club) is a graph describes a social network of 34 members of a karate club and documents links between members who interacted outside the club."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VIETqEfrfy5Y"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "networkx.classes.graph.Graph"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = nx.karate_club_graph()\n",
    "\n",
    "# G is an undirected graph\n",
    "type(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hDvf3nm-ors4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xujiaxing/anaconda/lib/python3.6/site-packages/networkx/drawing/nx_pylab.py:579: MatplotlibDeprecationWarning: \n",
      "The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead.\n",
      "  if not cb.iterable(width):\n"
     ]
    }
   ],
   "source": [
    "# Visualize the graph\n",
    "nx.draw(G, with_labels = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FX25Y1CrYmgN"
   },
   "source": [
    "## Question 1: What is the average degree of the karate club network? (5 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AUhES1VYo3tB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average degree of karate club network is 5\n"
     ]
    }
   ],
   "source": [
    "def average_degree(num_edges, num_nodes):\n",
    "  # TODO: Implement this function that takes number of edges\n",
    "  # and number of nodes, and returns the average node degree of \n",
    "  # the graph. Round the result to nearest integer (for example \n",
    "  # 3.3 will be rounded to 3 and 3.7 will be rounded to 4)\n",
    "\n",
    "  avg_degree = 0\n",
    "\n",
    "  ############# Your code here ############\n",
    "  avg_degree = round(2 * num_edges / num_nodes)\n",
    "  #########################################\n",
    "\n",
    "  return avg_degree\n",
    "\n",
    "num_edges = G.number_of_edges()\n",
    "num_nodes = G.number_of_nodes()\n",
    "avg_degree = average_degree(num_edges, num_nodes)\n",
    "print(\"Average degree of karate club network is {}\".format(avg_degree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fk02fD4vYmZI"
   },
   "source": [
    "## Question 2: What is the average clustering coefficient of the karate club network? (5 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "k15XKEto1aYJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average clustering coefficient of karate club network is 0.57\n"
     ]
    }
   ],
   "source": [
    "def average_clustering_coefficient(G):\n",
    "  # TODO: Implement this function that takes a nx.Graph\n",
    "  # and returns the average clustering coefficient. Round \n",
    "  # the result to 2 decimal places (for example 3.333 will\n",
    "  # be rounded to 3.33 and 3.7571 will be rounded to 3.76)\n",
    "\n",
    "  avg_cluster_coef = 0\n",
    "\n",
    "  ############# Your code here ############\n",
    "  ## Note: \n",
    "  ## 1: Please use the appropriate NetworkX clustering function\n",
    "  avg_cluster_coef = round(nx.average_clustering(G), 2)\n",
    "  #########################################\n",
    "\n",
    "  return avg_cluster_coef\n",
    "\n",
    "avg_cluster_coef = average_clustering_coefficient(G)\n",
    "print(\"Average clustering coefficient of karate club network is {}\".format(avg_cluster_coef))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zghQ-AhXYmP4"
   },
   "source": [
    "## Question 3: What is the PageRank value for node 0 (node with id 0) after one PageRank iteration? (5 Points)\n",
    "\n",
    "Please complete the code block by implementing the PageRank equation: $r_j = \\sum_{i \\rightarrow j} \\beta \\frac{r_i}{d_i} + (1 - \\beta) \\frac{1}{N}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BOGdWjNc6O7x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The PageRank value for node 0 after one iteration is 0.01\n"
     ]
    }
   ],
   "source": [
    "def one_iter_pagerank(G, beta, r0, node_id):\n",
    "  # TODO: Implement this function that takes a nx.Graph, beta, r0 and node id.\n",
    "  # The return value r1 is one interation PageRank value for the input node.\n",
    "  # Please round r1 to 2 decimal places.\n",
    "\n",
    "  r1 = 0\n",
    "\n",
    "  ############# Your code here ############\n",
    "  ## Note: \n",
    "  ## 1: You should not use nx.pagerank\n",
    "  r1 = round(beta * r0 / G.degree[node_id] + (1 - beta) / G.number_of_nodes(), 2)\n",
    "  #########################################\n",
    "\n",
    "  return r1\n",
    "\n",
    "beta = 0.8\n",
    "r0 = 1 / G.number_of_nodes()\n",
    "node = 0\n",
    "r1 = one_iter_pagerank(G, beta, r0, node)\n",
    "print(\"The PageRank value for node 0 after one iteration is {}\".format(r1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "icTcOULeYmIu"
   },
   "source": [
    "## Question 4: What is the (raw) closeness centrality for the karate club network node 5? (5 Points)\n",
    "\n",
    "The equation for closeness centrality is $c(v) = \\frac{1}{\\sum_{u \\neq v}\\text{shortest path length between } u \\text{ and } v}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "XbCsq_tl-3ok"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The karate club network has closeness centrality 12.66\n"
     ]
    }
   ],
   "source": [
    "def closeness_centrality(G, node=5):\n",
    "  # TODO: Implement the function that calculates closeness centrality \n",
    "  # for a node in karate club network. G is the input karate club \n",
    "  # network and node is the node id in the graph. Please round the \n",
    "  # closeness centrality result to 2 decimal places.\n",
    "\n",
    "  closeness = 0\n",
    "\n",
    "  ## Note:\n",
    "  ## 1: You can use networkx closeness centrality function.\n",
    "  ## 2: Notice that networkx closeness centrality returns the normalized \n",
    "  ## closeness directly, which is different from the raw (unnormalized) \n",
    "  ## one that we learned in the lecture.\n",
    "  closeness = round(nx.closeness_centrality(G)[node] * (G.number_of_nodes() - 1), 2)\n",
    "  #########################################\n",
    "\n",
    "  return closeness\n",
    "\n",
    "node = 5\n",
    "closeness = closeness_centrality(G, node=node)\n",
    "print(\"The karate club network has closeness centrality {}\".format(closeness))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-MxvowibYl4x"
   },
   "source": [
    "# 2 Graph to Tensor\n",
    "We will then work together to transform the graph $G$ into a PyTorch tensor, so that we can perform machine learning over the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDA8PosrA-9V"
   },
   "source": [
    "## Setup\n",
    "Check if PyTorch is properly installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ntuPVat_BAf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fko_2wSKYlun"
   },
   "source": [
    "## PyTorch tensor basics\n",
    "\n",
    "We can generate PyTorch tensor with all zeros, ones or random values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "W2ySw3m-A9qF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[0.0465, 0.2796, 0.4019, 0.9937],\n",
      "        [0.5921, 0.4480, 0.6897, 0.9407],\n",
      "        [0.1537, 0.4370, 0.2111, 0.8289]])\n",
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Generate 3 x 4 tensor with all ones\n",
    "ones = torch.ones(3, 4)\n",
    "print(ones)\n",
    "\n",
    "# Generate 3 x 4 tensor with all zeros\n",
    "zeros = torch.zeros(3, 4)\n",
    "print(zeros)\n",
    "\n",
    "# Generate 3 x 4 tensor with random values on the interval [0, 1)\n",
    "random_tensor = torch.rand(3, 4)\n",
    "print(random_tensor)\n",
    "\n",
    "# Get the shape of the tensor\n",
    "print(ones.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8mp66eHBxWC"
   },
   "source": [
    "PyTorch tensor contains elements for a single data type, the `dtype`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "rQiOvKJJBwq4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Create a 3 x 4 tensor with all 32-bit floating point zeros\n",
    "zeros = torch.zeros(3, 4, dtype=torch.float32)\n",
    "print(zeros.dtype)\n",
    "\n",
    "# Change the tensor dtype to 64-bit integer\n",
    "zeros = zeros.type(torch.long)\n",
    "print(zeros.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9EfegIRDkk2"
   },
   "source": [
    "## Question 5: Getting the edge list of the karate club network and transform it into `torch.LongTensor`. What is the `torch.sum` value of `pos_edge_index` tensor? (10 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "kEtVxMFID3ZT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pos_edge_index tensor has shape torch.Size([2, 78])\n",
      "The pos_edge_index tensor has sum value 2535\n"
     ]
    }
   ],
   "source": [
    "def graph_to_edge_list(G):\n",
    "  # TODO: Implement the function that returns the edge list of\n",
    "  # an nx.Graph. The returned edge_list should be a list of tuples\n",
    "  # where each tuple is a tuple representing an edge connected \n",
    "  # by two nodes.\n",
    "\n",
    "  edge_list = []\n",
    "\n",
    "  ############# Your code here ############\n",
    "  for edge in G.edges():\n",
    "    edge_list.append(edge)\n",
    "  #########################################\n",
    "\n",
    "  return edge_list\n",
    "\n",
    "def edge_list_to_tensor(edge_list):\n",
    "  # TODO: Implement the function that transforms the edge_list to\n",
    "  # tensor. The input edge_list is a list of tuples and the resulting\n",
    "  # tensor should have the shape [2 x len(edge_list)].\n",
    "\n",
    "  edge_index = torch.tensor([])\n",
    "\n",
    "  ############# Your code here ############\n",
    "  edge_index = torch.tensor(edge_list, dtype=torch.long).t()\n",
    "  #########################################\n",
    "\n",
    "  return edge_index\n",
    "\n",
    "pos_edge_list = graph_to_edge_list(G)\n",
    "pos_edge_index = edge_list_to_tensor(pos_edge_list)\n",
    "print(\"The pos_edge_index tensor has shape {}\".format(pos_edge_index.shape))\n",
    "print(\"The pos_edge_index tensor has sum value {}\".format(torch.sum(pos_edge_index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBL-ZmdHWqIu"
   },
   "source": [
    "## Question 6: Please implement following function that samples negative edges. Then you will answer which edges (edge_1 to edge_5) can be negative ones in the karate club network? (10 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9N8VT1f8-IJ8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The neg_edge_index tensor has shape torch.Size([2, 78])\n",
      "Can.\n",
      "Can't.\n",
      "Can.\n",
      "Can.\n",
      "Can't.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def sample_negative_edges(G, num_neg_samples):\n",
    "  # TODO: Implement the function that returns a list of negative edges.\n",
    "  # The number of sampled negative edges is num_neg_samples. You do not\n",
    "  # need to consider the corner case when the number of possible negative edges\n",
    "  # is less than num_neg_samples. It should be ok as long as your implementation \n",
    "  # works on the karate club network. In this implementation, self loop should \n",
    "  # not be considered as either a positive or negative edge. Also, notice that \n",
    "  # the karate club network is an undirected graph, if (0, 1) is a positive \n",
    "  # edge, do you think (1, 0) can be a negative one?\n",
    "\n",
    "  neg_edge_list = []\n",
    "\n",
    "  ############# Your code here ############\n",
    "  node_num = G.number_of_nodes()\n",
    "  def get_one_random_tuple():\n",
    "    return (random.randint(0, node_num - 1), random.randint(0, node_num - 1))\n",
    "  \n",
    "  def check_sample(sample):\n",
    "    return sample in neg_edge_list or sample in edge_list\n",
    "  \n",
    "  edge_list = graph_to_edge_list(G)\n",
    "  for i in range(num_neg_samples):\n",
    "    neg_sample = get_one_random_tuple()\n",
    "    while neg_sample[0] == neg_sample[1] or check_sample(neg_sample) or check_sample((neg_sample[1], neg_sample[0])):\n",
    "      neg_sample = get_one_random_tuple()\n",
    "    neg_edge_list.append(neg_sample)\n",
    "  #########################################\n",
    "\n",
    "  return neg_edge_list\n",
    "\n",
    "# Sample 78 negative edges\n",
    "neg_edge_list = sample_negative_edges(G, len(pos_edge_list))\n",
    "\n",
    "# Transform the negative edge list to tensor\n",
    "neg_edge_index = edge_list_to_tensor(neg_edge_list)\n",
    "print(\"The neg_edge_index tensor has shape {}\".format(neg_edge_index.shape))\n",
    "\n",
    "# Which of following edges can be negative ones?\n",
    "edge_1 = (7, 1)\n",
    "edge_2 = (1, 33)\n",
    "edge_3 = (33, 22)\n",
    "edge_4 = (0, 4)\n",
    "edge_5 = (4, 2)\n",
    "\n",
    "############# Your code here ############\n",
    "## Note:\n",
    "## 1: For each of the 5 edges, print whether it can be negative edge\n",
    "def check_neg_edge(edge):\n",
    "  if edge in pos_edge_list or (edge[1], edge[0]) in pos_edge_list:\n",
    "    print(\"Can.\")\n",
    "  else:\n",
    "    print(\"Can't.\")\n",
    "check_neg_edge(edge_1)\n",
    "check_neg_edge(edge_2)\n",
    "check_neg_edge(edge_3)\n",
    "check_neg_edge(edge_4)\n",
    "check_neg_edge(edge_5)\n",
    "#########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wk9Q-a-9qGsw"
   },
   "source": [
    "# 3 Node Emebedding Learning\n",
    "\n",
    "Finally, we will finish the first learning algorithm on graphs: a node embedding model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDBxRQcZ_dUH"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Lnqn9H6s_ehX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gomAf8vxq0R"
   },
   "source": [
    "To write our own node embedding learning methods, we'll heavily use the [`nn.Embedding`](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html) module in PyTorch. Let's see how to use `nn.Embedding`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "aRiWGuLAx5yx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample embedding layer: Embedding(4, 8)\n"
     ]
    }
   ],
   "source": [
    "# Initialize an embedding layer\n",
    "# Suppose we want to have embedding for 4 items (e.g., nodes)\n",
    "# Each item is represented with 8 dimensional vector\n",
    "\n",
    "emb_sample = nn.Embedding(num_embeddings=4, embedding_dim=8)\n",
    "print('Sample embedding layer: {}'.format(emb_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bS9qQfeujEVh"
   },
   "source": [
    "We can select items from the embedding matrix, by using Tensor indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "9AGIfP4QEDr8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8654,  0.0316,  0.7056,  1.0128, -0.0100,  0.1427,  1.4007,  1.3641]],\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "tensor([[-0.8654,  0.0316,  0.7056,  1.0128, -0.0100,  0.1427,  1.4007,  1.3641],\n",
      "        [-0.7064, -1.6043, -1.3518, -1.1396, -2.0267, -0.1858,  1.8215, -1.7032]],\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "torch.Size([4, 8])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]], grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Select an embedding in emb_sample\n",
    "id = torch.LongTensor([1])\n",
    "print(emb_sample(id))\n",
    "\n",
    "# Select multiple embeddings\n",
    "ids = torch.LongTensor([1, 3])\n",
    "print(emb_sample(ids))\n",
    "\n",
    "# Get the shape of the embedding weight matrix\n",
    "shape = emb_sample.weight.data.shape\n",
    "print(shape)\n",
    "\n",
    "# Overwrite the weight to tensor with all ones\n",
    "emb_sample.weight.data = torch.ones(shape)\n",
    "\n",
    "# Let's check if the emb is indeed initilized\n",
    "ids = torch.LongTensor([0, 3])\n",
    "print(emb_sample(ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8MjBuDKaKIsM"
   },
   "source": [
    "Now, it's your time to create node embedding matrix for the graph we have!\n",
    "- We want to have **16 dimensional** vector for each node in the karate club network.\n",
    "- We want to initalize the matrix under **uniform distribution**, in the range of $[0, 1)$. We suggest you using [`torch.rand`](https://pytorch.org/docs/stable/generated/torch.rand.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "hMszSwRPKGn1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding: Embedding(34, 16)\n",
      "tensor([[0.2114, 0.7335, 0.1433, 0.9647, 0.2933, 0.7951, 0.5170, 0.2801, 0.8339,\n",
      "         0.1185, 0.2355, 0.5599, 0.8966, 0.2858, 0.1955, 0.1808],\n",
      "        [0.7486, 0.6546, 0.3843, 0.9820, 0.6012, 0.3710, 0.4929, 0.9915, 0.8358,\n",
      "         0.4629, 0.9902, 0.7196, 0.2338, 0.0450, 0.7906, 0.9689]],\n",
      "       grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Please do not change / reset the random seed\n",
    "torch.manual_seed(1)\n",
    "\n",
    "def create_node_emb(num_node=34, embedding_dim=16):\n",
    "  # TODO: Implement this function that will create the node embedding matrix.\n",
    "  # A torch.nn.Embedding layer will be returned. You do not need to change \n",
    "  # the values of num_node and embedding_dim. The weight matrix of returned \n",
    "  # layer should be initialized under uniform distribution. \n",
    "\n",
    "  emb = None\n",
    "\n",
    "  ############# Your code here ############\n",
    "  emb = nn.Embedding(num_embeddings=num_node, embedding_dim=embedding_dim)\n",
    "  shape = emb.weight.data.shape\n",
    "  emb.weight.data = torch.rand(shape)\n",
    "  #########################################\n",
    "\n",
    "  return emb\n",
    "\n",
    "emb = create_node_emb()\n",
    "ids = torch.LongTensor([0, 3])\n",
    "\n",
    "# Print the embedding layer\n",
    "print(\"Embedding: {}\".format(emb))\n",
    "\n",
    "# An example that gets the embeddings for node 0 and 3\n",
    "print(emb(ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4QfoANibTzyh"
   },
   "source": [
    "## Visualize the initial node embeddings\n",
    "One good way to understand an embedding matrix, is to visualize it in a 2D space.\n",
    "Here, we have implemented an embedding visualization function for you.\n",
    "We first do PCA to reduce the dimensionality of embeddings to a 2D space.\n",
    "Then visualize each point, colored by the community it belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "_LCoIkarhfYD"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb4AAAEuCAYAAADx63eqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAFlCAYAAADoPlOZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGPiSVBIGviSVxP8HjRZxjDFETzAAAAAASURBVDWvBh4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_emb(emb):\n",
    "  X = emb.weight.data.numpy()\n",
    "  pca = PCA(n_components=2)\n",
    "  components = pca.fit_transform(X)\n",
    "  plt.figure(figsize=(6, 6))\n",
    "  club1_x = []\n",
    "  club1_y = []\n",
    "  club2_x = []\n",
    "  club2_y = []\n",
    "  for node in G.nodes(data=True):\n",
    "    if node[1]['club'] == 'Mr. Hi':\n",
    "      club1_x.append(components[node[0]][0])\n",
    "      club1_y.append(components[node[0]][1])\n",
    "    else:\n",
    "      club2_x.append(components[node[0]][0])\n",
    "      club2_y.append(components[node[0]][1])\n",
    "  plt.scatter(club1_x, club1_y, color=\"red\", label=\"Mr. Hi\")\n",
    "  plt.scatter(club2_x, club2_y, color=\"blue\", label=\"Officer\")\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "# Visualize the initial random embeddding\n",
    "visualize_emb(emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQIyuEz9ANb2"
   },
   "source": [
    "## Question 7: Training the embedding! What is the best performance you can get? Please report both the best loss and accuracy on Gradescope. (20 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "RDeQTNNxqH0j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch 0=====\n",
      "Loss: tensor(2.0190, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.5\n",
      "\n",
      "=====Epoch 1=====\n",
      "Loss: tensor(2.0047, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.5\n",
      "\n",
      "=====Epoch 2=====\n",
      "Loss: tensor(1.9779, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.5\n",
      "\n",
      "=====Epoch 3=====\n",
      "Loss: tensor(1.9401, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.5\n",
      "\n",
      "=====Epoch 4=====\n",
      "Loss: tensor(1.8931, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.5\n",
      "\n",
      "=====Epoch 5=====\n",
      "Loss: tensor(1.8385, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.5\n",
      "\n",
      "=====Epoch 6=====\n",
      "Loss: tensor(1.7778, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.5\n",
      "\n",
      "=====Epoch 7=====\n",
      "Loss: tensor(1.7125, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.5\n",
      "\n",
      "=====Epoch 8=====\n",
      "Loss: tensor(1.6441, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.5\n",
      "\n",
      "=====Epoch 9=====\n",
      "Loss: tensor(1.5737, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.5\n",
      "\n",
      "=====Epoch 10=====\n",
      "Loss: tensor(1.5025, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.5\n",
      "\n",
      "=====Epoch 11=====\n",
      "Loss: tensor(1.4315, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.5\n",
      "\n",
      "=====Epoch 12=====\n",
      "Loss: tensor(1.3617, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.5\n",
      "\n",
      "=====Epoch 13=====\n",
      "Loss: tensor(1.2938, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.5\n",
      "\n",
      "=====Epoch 14=====\n",
      "Loss: tensor(1.2284, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.5\n",
      "\n",
      "=====Epoch 15=====\n",
      "Loss: tensor(1.1661, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.5064\n",
      "\n",
      "=====Epoch 16=====\n",
      "Loss: tensor(1.1072, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.5064\n",
      "\n",
      "=====Epoch 17=====\n",
      "Loss: tensor(1.0519, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.5064\n",
      "\n",
      "=====Epoch 18=====\n",
      "Loss: tensor(1.0005, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.5064\n",
      "\n",
      "=====Epoch 19=====\n",
      "Loss: tensor(0.9530, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.5064\n",
      "\n",
      "=====Epoch 20=====\n",
      "Loss: tensor(0.9094, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.5064\n",
      "\n",
      "=====Epoch 21=====\n",
      "Loss: tensor(0.8694, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.5128\n",
      "\n",
      "=====Epoch 22=====\n",
      "Loss: tensor(0.8331, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.5256\n",
      "\n",
      "=====Epoch 23=====\n",
      "Loss: tensor(0.8002, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.5321\n",
      "\n",
      "=====Epoch 24=====\n",
      "Loss: tensor(0.7704, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.5385\n",
      "\n",
      "=====Epoch 25=====\n",
      "Loss: tensor(0.7437, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.5385\n",
      "\n",
      "=====Epoch 26=====\n",
      "Loss: tensor(0.7196, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.5449\n",
      "\n",
      "=====Epoch 27=====\n",
      "Loss: tensor(0.6979, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.5641\n",
      "\n",
      "=====Epoch 28=====\n",
      "Loss: tensor(0.6785, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.5833\n",
      "\n",
      "=====Epoch 29=====\n",
      "Loss: tensor(0.6611, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.5897\n",
      "\n",
      "=====Epoch 30=====\n",
      "Loss: tensor(0.6455, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.5897\n",
      "\n",
      "=====Epoch 31=====\n",
      "Loss: tensor(0.6315, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.6026\n",
      "\n",
      "=====Epoch 32=====\n",
      "Loss: tensor(0.6188, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.6282\n",
      "\n",
      "=====Epoch 33=====\n",
      "Loss: tensor(0.6074, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.6538\n",
      "\n",
      "=====Epoch 34=====\n",
      "Loss: tensor(0.5971, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.6667\n",
      "\n",
      "=====Epoch 35=====\n",
      "Loss: tensor(0.5877, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.6667\n",
      "\n",
      "=====Epoch 36=====\n",
      "Loss: tensor(0.5792, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.6603\n",
      "\n",
      "=====Epoch 37=====\n",
      "Loss: tensor(0.5714, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.6859\n",
      "\n",
      "=====Epoch 38=====\n",
      "Loss: tensor(0.5642, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.6923\n",
      "\n",
      "=====Epoch 39=====\n",
      "Loss: tensor(0.5575, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.6923\n",
      "\n",
      "=====Epoch 40=====\n",
      "Loss: tensor(0.5513, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.6987\n",
      "\n",
      "=====Epoch 41=====\n",
      "Loss: tensor(0.5456, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.7115\n",
      "\n",
      "=====Epoch 42=====\n",
      "Loss: tensor(0.5401, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.7115\n",
      "\n",
      "=====Epoch 43=====\n",
      "Loss: tensor(0.5350, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.7244\n",
      "\n",
      "=====Epoch 44=====\n",
      "Loss: tensor(0.5301, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.7179\n",
      "\n",
      "=====Epoch 45=====\n",
      "Loss: tensor(0.5255, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.7244\n",
      "\n",
      "=====Epoch 46=====\n",
      "Loss: tensor(0.5210, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.7244\n",
      "\n",
      "=====Epoch 47=====\n",
      "Loss: tensor(0.5167, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.7372\n",
      "\n",
      "=====Epoch 48=====\n",
      "Loss: tensor(0.5125, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.7436\n",
      "\n",
      "=====Epoch 49=====\n",
      "Loss: tensor(0.5085, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.7564\n",
      "\n",
      "=====Epoch 50=====\n",
      "Loss: tensor(0.5046, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.7628\n",
      "\n",
      "=====Epoch 51=====\n",
      "Loss: tensor(0.5007, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.7756\n",
      "\n",
      "=====Epoch 52=====\n",
      "Loss: tensor(0.4969, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.7821\n",
      "\n",
      "=====Epoch 53=====\n",
      "Loss: tensor(0.4932, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.7949\n",
      "\n",
      "=====Epoch 54=====\n",
      "Loss: tensor(0.4895, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.7949\n",
      "\n",
      "=====Epoch 55=====\n",
      "Loss: tensor(0.4859, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.8013\n",
      "\n",
      "=====Epoch 56=====\n",
      "Loss: tensor(0.4824, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.8013\n",
      "\n",
      "=====Epoch 57=====\n",
      "Loss: tensor(0.4788, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.8013\n",
      "\n",
      "=====Epoch 58=====\n",
      "Loss: tensor(0.4753, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.8013\n",
      "\n",
      "=====Epoch 59=====\n",
      "Loss: tensor(0.4718, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.8013\n",
      "\n",
      "=====Epoch 60=====\n",
      "Loss: tensor(0.4684, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.8013\n",
      "\n",
      "=====Epoch 61=====\n",
      "Loss: tensor(0.4649, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.8141\n",
      "\n",
      "=====Epoch 62=====\n",
      "Loss: tensor(0.4615, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.8141\n",
      "\n",
      "=====Epoch 63=====\n",
      "Loss: tensor(0.4581, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.8141\n",
      "\n",
      "=====Epoch 64=====\n",
      "Loss: tensor(0.4548, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.8141\n",
      "\n",
      "=====Epoch 65=====\n",
      "Loss: tensor(0.4514, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.8141\n",
      "\n",
      "=====Epoch 66=====\n",
      "Loss: tensor(0.4481, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.8269\n",
      "\n",
      "=====Epoch 67=====\n",
      "Loss: tensor(0.4447, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.8269\n",
      "\n",
      "=====Epoch 68=====\n",
      "Loss: tensor(0.4414, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.8269\n",
      "\n",
      "=====Epoch 69=====\n",
      "Loss: tensor(0.4381, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.8333\n",
      "\n",
      "=====Epoch 70=====\n",
      "Loss: tensor(0.4348, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.8333\n",
      "\n",
      "=====Epoch 71=====\n",
      "Loss: tensor(0.4315, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.8397\n",
      "\n",
      "=====Epoch 72=====\n",
      "Loss: tensor(0.4283, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.8526\n",
      "\n",
      "=====Epoch 73=====\n",
      "Loss: tensor(0.4250, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.8526\n",
      "\n",
      "=====Epoch 74=====\n",
      "Loss: tensor(0.4218, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.8526\n",
      "\n",
      "=====Epoch 75=====\n",
      "Loss: tensor(0.4185, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.8654\n",
      "\n",
      "=====Epoch 76=====\n",
      "Loss: tensor(0.4153, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.8718\n",
      "\n",
      "=====Epoch 77=====\n",
      "Loss: tensor(0.4121, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.8782\n",
      "\n",
      "=====Epoch 78=====\n",
      "Loss: tensor(0.4089, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.8782\n",
      "\n",
      "=====Epoch 79=====\n",
      "Loss: tensor(0.4057, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.8782\n",
      "\n",
      "=====Epoch 80=====\n",
      "Loss: tensor(0.4025, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.8846\n",
      "\n",
      "=====Epoch 81=====\n",
      "Loss: tensor(0.3994, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.8846\n",
      "\n",
      "=====Epoch 82=====\n",
      "Loss: tensor(0.3962, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.891\n",
      "\n",
      "=====Epoch 83=====\n",
      "Loss: tensor(0.3931, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.891\n",
      "\n",
      "=====Epoch 84=====\n",
      "Loss: tensor(0.3900, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.8974\n",
      "\n",
      "=====Epoch 85=====\n",
      "Loss: tensor(0.3869, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.8974\n",
      "\n",
      "=====Epoch 86=====\n",
      "Loss: tensor(0.3838, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.8974\n",
      "\n",
      "=====Epoch 87=====\n",
      "Loss: tensor(0.3807, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.8974\n",
      "\n",
      "=====Epoch 88=====\n",
      "Loss: tensor(0.3776, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9038\n",
      "\n",
      "=====Epoch 89=====\n",
      "Loss: tensor(0.3745, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9167\n",
      "\n",
      "=====Epoch 90=====\n",
      "Loss: tensor(0.3715, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9167\n",
      "\n",
      "=====Epoch 91=====\n",
      "Loss: tensor(0.3684, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9167\n",
      "\n",
      "=====Epoch 92=====\n",
      "Loss: tensor(0.3654, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9167\n",
      "\n",
      "=====Epoch 93=====\n",
      "Loss: tensor(0.3624, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9167\n",
      "\n",
      "=====Epoch 94=====\n",
      "Loss: tensor(0.3594, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9167\n",
      "\n",
      "=====Epoch 95=====\n",
      "Loss: tensor(0.3564, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9167\n",
      "\n",
      "=====Epoch 96=====\n",
      "Loss: tensor(0.3534, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9167\n",
      "\n",
      "=====Epoch 97=====\n",
      "Loss: tensor(0.3504, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9167\n",
      "\n",
      "=====Epoch 98=====\n",
      "Loss: tensor(0.3475, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9231\n",
      "\n",
      "=====Epoch 99=====\n",
      "Loss: tensor(0.3446, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9359\n",
      "\n",
      "=====Epoch 100=====\n",
      "Loss: tensor(0.3416, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9423\n",
      "\n",
      "=====Epoch 101=====\n",
      "Loss: tensor(0.3387, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9423\n",
      "\n",
      "=====Epoch 102=====\n",
      "Loss: tensor(0.3358, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9423\n",
      "\n",
      "=====Epoch 103=====\n",
      "Loss: tensor(0.3329, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9423\n",
      "\n",
      "=====Epoch 104=====\n",
      "Loss: tensor(0.3301, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9423\n",
      "\n",
      "=====Epoch 105=====\n",
      "Loss: tensor(0.3272, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9423\n",
      "\n",
      "=====Epoch 106=====\n",
      "Loss: tensor(0.3244, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9423\n",
      "\n",
      "=====Epoch 107=====\n",
      "Loss: tensor(0.3215, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9423\n",
      "\n",
      "=====Epoch 108=====\n",
      "Loss: tensor(0.3187, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9487\n",
      "\n",
      "=====Epoch 109=====\n",
      "Loss: tensor(0.3159, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9487\n",
      "\n",
      "=====Epoch 110=====\n",
      "Loss: tensor(0.3131, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9487\n",
      "\n",
      "=====Epoch 111=====\n",
      "Loss: tensor(0.3103, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9487\n",
      "\n",
      "=====Epoch 112=====\n",
      "Loss: tensor(0.3076, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9551\n",
      "\n",
      "=====Epoch 113=====\n",
      "Loss: tensor(0.3048, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9551\n",
      "\n",
      "=====Epoch 114=====\n",
      "Loss: tensor(0.3021, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9551\n",
      "\n",
      "=====Epoch 115=====\n",
      "Loss: tensor(0.2994, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9551\n",
      "\n",
      "=====Epoch 116=====\n",
      "Loss: tensor(0.2967, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9551\n",
      "\n",
      "=====Epoch 117=====\n",
      "Loss: tensor(0.2940, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9551\n",
      "\n",
      "=====Epoch 118=====\n",
      "Loss: tensor(0.2913, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9551\n",
      "\n",
      "=====Epoch 119=====\n",
      "Loss: tensor(0.2887, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9551\n",
      "\n",
      "=====Epoch 120=====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.2860, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9551\n",
      "\n",
      "=====Epoch 121=====\n",
      "Loss: tensor(0.2834, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9551\n",
      "\n",
      "=====Epoch 122=====\n",
      "Loss: tensor(0.2808, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9551\n",
      "\n",
      "=====Epoch 123=====\n",
      "Loss: tensor(0.2782, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9551\n",
      "\n",
      "=====Epoch 124=====\n",
      "Loss: tensor(0.2756, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9551\n",
      "\n",
      "=====Epoch 125=====\n",
      "Loss: tensor(0.2731, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9615\n",
      "\n",
      "=====Epoch 126=====\n",
      "Loss: tensor(0.2705, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9615\n",
      "\n",
      "=====Epoch 127=====\n",
      "Loss: tensor(0.2680, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9615\n",
      "\n",
      "=====Epoch 128=====\n",
      "Loss: tensor(0.2655, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9615\n",
      "\n",
      "=====Epoch 129=====\n",
      "Loss: tensor(0.2630, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9615\n",
      "\n",
      "=====Epoch 130=====\n",
      "Loss: tensor(0.2605, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9615\n",
      "\n",
      "=====Epoch 131=====\n",
      "Loss: tensor(0.2580, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9679\n",
      "\n",
      "=====Epoch 132=====\n",
      "Loss: tensor(0.2556, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9679\n",
      "\n",
      "=====Epoch 133=====\n",
      "Loss: tensor(0.2531, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9679\n",
      "\n",
      "=====Epoch 134=====\n",
      "Loss: tensor(0.2507, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9679\n",
      "\n",
      "=====Epoch 135=====\n",
      "Loss: tensor(0.2483, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9679\n",
      "\n",
      "=====Epoch 136=====\n",
      "Loss: tensor(0.2459, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9679\n",
      "\n",
      "=====Epoch 137=====\n",
      "Loss: tensor(0.2436, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9679\n",
      "\n",
      "=====Epoch 138=====\n",
      "Loss: tensor(0.2412, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9679\n",
      "\n",
      "=====Epoch 139=====\n",
      "Loss: tensor(0.2389, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9744\n",
      "\n",
      "=====Epoch 140=====\n",
      "Loss: tensor(0.2365, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9744\n",
      "\n",
      "=====Epoch 141=====\n",
      "Loss: tensor(0.2342, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9744\n",
      "\n",
      "=====Epoch 142=====\n",
      "Loss: tensor(0.2320, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9808\n",
      "\n",
      "=====Epoch 143=====\n",
      "Loss: tensor(0.2297, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9808\n",
      "\n",
      "=====Epoch 144=====\n",
      "Loss: tensor(0.2274, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9808\n",
      "\n",
      "=====Epoch 145=====\n",
      "Loss: tensor(0.2252, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9808\n",
      "\n",
      "=====Epoch 146=====\n",
      "Loss: tensor(0.2230, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9808\n",
      "\n",
      "=====Epoch 147=====\n",
      "Loss: tensor(0.2208, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9808\n",
      "\n",
      "=====Epoch 148=====\n",
      "Loss: tensor(0.2186, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9808\n",
      "\n",
      "=====Epoch 149=====\n",
      "Loss: tensor(0.2164, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9808\n",
      "\n",
      "=====Epoch 150=====\n",
      "Loss: tensor(0.2143, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9808\n",
      "\n",
      "=====Epoch 151=====\n",
      "Loss: tensor(0.2122, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9808\n",
      "\n",
      "=====Epoch 152=====\n",
      "Loss: tensor(0.2101, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9808\n",
      "\n",
      "=====Epoch 153=====\n",
      "Loss: tensor(0.2080, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9808\n",
      "\n",
      "=====Epoch 154=====\n",
      "Loss: tensor(0.2059, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9808\n",
      "\n",
      "=====Epoch 155=====\n",
      "Loss: tensor(0.2038, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9808\n",
      "\n",
      "=====Epoch 156=====\n",
      "Loss: tensor(0.2018, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9872\n",
      "\n",
      "=====Epoch 157=====\n",
      "Loss: tensor(0.1998, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9872\n",
      "\n",
      "=====Epoch 158=====\n",
      "Loss: tensor(0.1977, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9872\n",
      "\n",
      "=====Epoch 159=====\n",
      "Loss: tensor(0.1958, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9872\n",
      "\n",
      "=====Epoch 160=====\n",
      "Loss: tensor(0.1938, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9872\n",
      "\n",
      "=====Epoch 161=====\n",
      "Loss: tensor(0.1918, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9872\n",
      "\n",
      "=====Epoch 162=====\n",
      "Loss: tensor(0.1899, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9872\n",
      "\n",
      "=====Epoch 163=====\n",
      "Loss: tensor(0.1880, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9872\n",
      "\n",
      "=====Epoch 164=====\n",
      "Loss: tensor(0.1861, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9872\n",
      "\n",
      "=====Epoch 165=====\n",
      "Loss: tensor(0.1842, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9872\n",
      "\n",
      "=====Epoch 166=====\n",
      "Loss: tensor(0.1823, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9872\n",
      "\n",
      "=====Epoch 167=====\n",
      "Loss: tensor(0.1805, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9872\n",
      "\n",
      "=====Epoch 168=====\n",
      "Loss: tensor(0.1786, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9872\n",
      "\n",
      "=====Epoch 169=====\n",
      "Loss: tensor(0.1768, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9872\n",
      "\n",
      "=====Epoch 170=====\n",
      "Loss: tensor(0.1750, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9872\n",
      "\n",
      "=====Epoch 171=====\n",
      "Loss: tensor(0.1732, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9872\n",
      "\n",
      "=====Epoch 172=====\n",
      "Loss: tensor(0.1715, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9872\n",
      "\n",
      "=====Epoch 173=====\n",
      "Loss: tensor(0.1697, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9872\n",
      "\n",
      "=====Epoch 174=====\n",
      "Loss: tensor(0.1680, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9872\n",
      "\n",
      "=====Epoch 175=====\n",
      "Loss: tensor(0.1663, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9872\n",
      "\n",
      "=====Epoch 176=====\n",
      "Loss: tensor(0.1646, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9936\n",
      "\n",
      "=====Epoch 177=====\n",
      "Loss: tensor(0.1629, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9936\n",
      "\n",
      "=====Epoch 178=====\n",
      "Loss: tensor(0.1612, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9936\n",
      "\n",
      "=====Epoch 179=====\n",
      "Loss: tensor(0.1596, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9936\n",
      "\n",
      "=====Epoch 180=====\n",
      "Loss: tensor(0.1580, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9936\n",
      "\n",
      "=====Epoch 181=====\n",
      "Loss: tensor(0.1563, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9936\n",
      "\n",
      "=====Epoch 182=====\n",
      "Loss: tensor(0.1547, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9936\n",
      "\n",
      "=====Epoch 183=====\n",
      "Loss: tensor(0.1532, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9936\n",
      "\n",
      "=====Epoch 184=====\n",
      "Loss: tensor(0.1516, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9936\n",
      "\n",
      "=====Epoch 185=====\n",
      "Loss: tensor(0.1501, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 0.9936\n",
      "\n",
      "=====Epoch 186=====\n",
      "Loss: tensor(0.1485, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 187=====\n",
      "Loss: tensor(0.1470, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 188=====\n",
      "Loss: tensor(0.1455, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 189=====\n",
      "Loss: tensor(0.1441, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 190=====\n",
      "Loss: tensor(0.1426, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 191=====\n",
      "Loss: tensor(0.1411, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 192=====\n",
      "Loss: tensor(0.1397, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 193=====\n",
      "Loss: tensor(0.1383, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 194=====\n",
      "Loss: tensor(0.1369, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 195=====\n",
      "Loss: tensor(0.1355, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 196=====\n",
      "Loss: tensor(0.1342, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 197=====\n",
      "Loss: tensor(0.1328, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 198=====\n",
      "Loss: tensor(0.1315, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 199=====\n",
      "Loss: tensor(0.1301, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 200=====\n",
      "Loss: tensor(0.1288, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 201=====\n",
      "Loss: tensor(0.1276, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 202=====\n",
      "Loss: tensor(0.1263, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 203=====\n",
      "Loss: tensor(0.1250, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 204=====\n",
      "Loss: tensor(0.1238, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 205=====\n",
      "Loss: tensor(0.1225, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 206=====\n",
      "Loss: tensor(0.1213, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 207=====\n",
      "Loss: tensor(0.1201, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 208=====\n",
      "Loss: tensor(0.1189, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 209=====\n",
      "Loss: tensor(0.1178, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 210=====\n",
      "Loss: tensor(0.1166, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 211=====\n",
      "Loss: tensor(0.1155, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 212=====\n",
      "Loss: tensor(0.1143, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 213=====\n",
      "Loss: tensor(0.1132, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 214=====\n",
      "Loss: tensor(0.1121, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 215=====\n",
      "Loss: tensor(0.1110, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 216=====\n",
      "Loss: tensor(0.1099, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 217=====\n",
      "Loss: tensor(0.1089, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 218=====\n",
      "Loss: tensor(0.1078, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 219=====\n",
      "Loss: tensor(0.1068, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 220=====\n",
      "Loss: tensor(0.1058, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 221=====\n",
      "Loss: tensor(0.1047, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 222=====\n",
      "Loss: tensor(0.1037, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 223=====\n",
      "Loss: tensor(0.1027, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 224=====\n",
      "Loss: tensor(0.1018, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 225=====\n",
      "Loss: tensor(0.1008, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 226=====\n",
      "Loss: tensor(0.0999, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 227=====\n",
      "Loss: tensor(0.0989, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 228=====\n",
      "Loss: tensor(0.0980, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 229=====\n",
      "Loss: tensor(0.0971, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 230=====\n",
      "Loss: tensor(0.0962, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 231=====\n",
      "Loss: tensor(0.0953, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 232=====\n",
      "Loss: tensor(0.0944, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 233=====\n",
      "Loss: tensor(0.0935, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 234=====\n",
      "Loss: tensor(0.0926, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 235=====\n",
      "Loss: tensor(0.0918, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 236=====\n",
      "Loss: tensor(0.0910, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 237=====\n",
      "Loss: tensor(0.0901, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 238=====\n",
      "Loss: tensor(0.0893, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 239=====\n",
      "Loss: tensor(0.0885, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 240=====\n",
      "Loss: tensor(0.0877, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 241=====\n",
      "Loss: tensor(0.0869, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 242=====\n",
      "Loss: tensor(0.0861, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch 243=====\n",
      "Loss: tensor(0.0854, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 244=====\n",
      "Loss: tensor(0.0846, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 245=====\n",
      "Loss: tensor(0.0839, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 246=====\n",
      "Loss: tensor(0.0831, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 247=====\n",
      "Loss: tensor(0.0824, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 248=====\n",
      "Loss: tensor(0.0817, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 249=====\n",
      "Loss: tensor(0.0809, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 250=====\n",
      "Loss: tensor(0.0802, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 251=====\n",
      "Loss: tensor(0.0795, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 252=====\n",
      "Loss: tensor(0.0789, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 253=====\n",
      "Loss: tensor(0.0782, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 254=====\n",
      "Loss: tensor(0.0775, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 255=====\n",
      "Loss: tensor(0.0768, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 256=====\n",
      "Loss: tensor(0.0762, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 257=====\n",
      "Loss: tensor(0.0755, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 258=====\n",
      "Loss: tensor(0.0749, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 259=====\n",
      "Loss: tensor(0.0743, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 260=====\n",
      "Loss: tensor(0.0737, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 261=====\n",
      "Loss: tensor(0.0730, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 262=====\n",
      "Loss: tensor(0.0724, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 263=====\n",
      "Loss: tensor(0.0718, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 264=====\n",
      "Loss: tensor(0.0712, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 265=====\n",
      "Loss: tensor(0.0707, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 266=====\n",
      "Loss: tensor(0.0701, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 267=====\n",
      "Loss: tensor(0.0695, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 268=====\n",
      "Loss: tensor(0.0689, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 269=====\n",
      "Loss: tensor(0.0684, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 270=====\n",
      "Loss: tensor(0.0678, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 271=====\n",
      "Loss: tensor(0.0673, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 272=====\n",
      "Loss: tensor(0.0668, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 273=====\n",
      "Loss: tensor(0.0662, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 274=====\n",
      "Loss: tensor(0.0657, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 275=====\n",
      "Loss: tensor(0.0652, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 276=====\n",
      "Loss: tensor(0.0647, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 277=====\n",
      "Loss: tensor(0.0642, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 278=====\n",
      "Loss: tensor(0.0637, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 279=====\n",
      "Loss: tensor(0.0632, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 280=====\n",
      "Loss: tensor(0.0627, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 281=====\n",
      "Loss: tensor(0.0622, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 282=====\n",
      "Loss: tensor(0.0617, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 283=====\n",
      "Loss: tensor(0.0613, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 284=====\n",
      "Loss: tensor(0.0608, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 285=====\n",
      "Loss: tensor(0.0603, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 286=====\n",
      "Loss: tensor(0.0599, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 287=====\n",
      "Loss: tensor(0.0594, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 288=====\n",
      "Loss: tensor(0.0590, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 289=====\n",
      "Loss: tensor(0.0585, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 290=====\n",
      "Loss: tensor(0.0581, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 291=====\n",
      "Loss: tensor(0.0577, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 292=====\n",
      "Loss: tensor(0.0573, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 293=====\n",
      "Loss: tensor(0.0568, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 294=====\n",
      "Loss: tensor(0.0564, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 295=====\n",
      "Loss: tensor(0.0560, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 296=====\n",
      "Loss: tensor(0.0556, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 297=====\n",
      "Loss: tensor(0.0552, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 298=====\n",
      "Loss: tensor(0.0548, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 299=====\n",
      "Loss: tensor(0.0544, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 300=====\n",
      "Loss: tensor(0.0540, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 301=====\n",
      "Loss: tensor(0.0537, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 302=====\n",
      "Loss: tensor(0.0533, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 303=====\n",
      "Loss: tensor(0.0529, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 304=====\n",
      "Loss: tensor(0.0525, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 305=====\n",
      "Loss: tensor(0.0522, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 306=====\n",
      "Loss: tensor(0.0518, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 307=====\n",
      "Loss: tensor(0.0514, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 308=====\n",
      "Loss: tensor(0.0511, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 309=====\n",
      "Loss: tensor(0.0507, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 310=====\n",
      "Loss: tensor(0.0504, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 311=====\n",
      "Loss: tensor(0.0500, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 312=====\n",
      "Loss: tensor(0.0497, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 313=====\n",
      "Loss: tensor(0.0494, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 314=====\n",
      "Loss: tensor(0.0490, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 315=====\n",
      "Loss: tensor(0.0487, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 316=====\n",
      "Loss: tensor(0.0484, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 317=====\n",
      "Loss: tensor(0.0481, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 318=====\n",
      "Loss: tensor(0.0478, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 319=====\n",
      "Loss: tensor(0.0474, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 320=====\n",
      "Loss: tensor(0.0471, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 321=====\n",
      "Loss: tensor(0.0468, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 322=====\n",
      "Loss: tensor(0.0465, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 323=====\n",
      "Loss: tensor(0.0462, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 324=====\n",
      "Loss: tensor(0.0459, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 325=====\n",
      "Loss: tensor(0.0456, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 326=====\n",
      "Loss: tensor(0.0453, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 327=====\n",
      "Loss: tensor(0.0450, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 328=====\n",
      "Loss: tensor(0.0448, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 329=====\n",
      "Loss: tensor(0.0445, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 330=====\n",
      "Loss: tensor(0.0442, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 331=====\n",
      "Loss: tensor(0.0439, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 332=====\n",
      "Loss: tensor(0.0436, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 333=====\n",
      "Loss: tensor(0.0434, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 334=====\n",
      "Loss: tensor(0.0431, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 335=====\n",
      "Loss: tensor(0.0428, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 336=====\n",
      "Loss: tensor(0.0426, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 337=====\n",
      "Loss: tensor(0.0423, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 338=====\n",
      "Loss: tensor(0.0421, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 339=====\n",
      "Loss: tensor(0.0418, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 340=====\n",
      "Loss: tensor(0.0415, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 341=====\n",
      "Loss: tensor(0.0413, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 342=====\n",
      "Loss: tensor(0.0410, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 343=====\n",
      "Loss: tensor(0.0408, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 344=====\n",
      "Loss: tensor(0.0406, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 345=====\n",
      "Loss: tensor(0.0403, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 346=====\n",
      "Loss: tensor(0.0401, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 347=====\n",
      "Loss: tensor(0.0398, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 348=====\n",
      "Loss: tensor(0.0396, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 349=====\n",
      "Loss: tensor(0.0394, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 350=====\n",
      "Loss: tensor(0.0392, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 351=====\n",
      "Loss: tensor(0.0389, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 352=====\n",
      "Loss: tensor(0.0387, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 353=====\n",
      "Loss: tensor(0.0385, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch 354=====\n",
      "Loss: tensor(0.0383, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 355=====\n",
      "Loss: tensor(0.0380, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 356=====\n",
      "Loss: tensor(0.0378, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 357=====\n",
      "Loss: tensor(0.0376, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 358=====\n",
      "Loss: tensor(0.0374, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 359=====\n",
      "Loss: tensor(0.0372, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 360=====\n",
      "Loss: tensor(0.0370, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 361=====\n",
      "Loss: tensor(0.0368, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 362=====\n",
      "Loss: tensor(0.0366, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 363=====\n",
      "Loss: tensor(0.0364, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 364=====\n",
      "Loss: tensor(0.0362, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 365=====\n",
      "Loss: tensor(0.0360, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 366=====\n",
      "Loss: tensor(0.0358, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 367=====\n",
      "Loss: tensor(0.0356, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 368=====\n",
      "Loss: tensor(0.0354, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 369=====\n",
      "Loss: tensor(0.0352, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 370=====\n",
      "Loss: tensor(0.0350, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 371=====\n",
      "Loss: tensor(0.0348, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 372=====\n",
      "Loss: tensor(0.0346, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 373=====\n",
      "Loss: tensor(0.0344, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 374=====\n",
      "Loss: tensor(0.0343, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 375=====\n",
      "Loss: tensor(0.0341, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 376=====\n",
      "Loss: tensor(0.0339, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 377=====\n",
      "Loss: tensor(0.0337, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 378=====\n",
      "Loss: tensor(0.0335, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 379=====\n",
      "Loss: tensor(0.0334, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 380=====\n",
      "Loss: tensor(0.0332, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 381=====\n",
      "Loss: tensor(0.0330, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 382=====\n",
      "Loss: tensor(0.0328, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 383=====\n",
      "Loss: tensor(0.0327, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 384=====\n",
      "Loss: tensor(0.0325, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 385=====\n",
      "Loss: tensor(0.0323, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 386=====\n",
      "Loss: tensor(0.0322, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 387=====\n",
      "Loss: tensor(0.0320, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 388=====\n",
      "Loss: tensor(0.0318, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 389=====\n",
      "Loss: tensor(0.0317, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 390=====\n",
      "Loss: tensor(0.0315, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 391=====\n",
      "Loss: tensor(0.0314, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 392=====\n",
      "Loss: tensor(0.0312, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 393=====\n",
      "Loss: tensor(0.0311, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 394=====\n",
      "Loss: tensor(0.0309, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 395=====\n",
      "Loss: tensor(0.0308, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 396=====\n",
      "Loss: tensor(0.0306, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 397=====\n",
      "Loss: tensor(0.0304, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 398=====\n",
      "Loss: tensor(0.0303, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 399=====\n",
      "Loss: tensor(0.0302, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 400=====\n",
      "Loss: tensor(0.0300, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 401=====\n",
      "Loss: tensor(0.0299, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 402=====\n",
      "Loss: tensor(0.0297, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 403=====\n",
      "Loss: tensor(0.0296, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 404=====\n",
      "Loss: tensor(0.0294, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 405=====\n",
      "Loss: tensor(0.0293, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 406=====\n",
      "Loss: tensor(0.0292, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 407=====\n",
      "Loss: tensor(0.0290, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 408=====\n",
      "Loss: tensor(0.0289, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 409=====\n",
      "Loss: tensor(0.0287, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 410=====\n",
      "Loss: tensor(0.0286, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 411=====\n",
      "Loss: tensor(0.0285, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 412=====\n",
      "Loss: tensor(0.0283, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 413=====\n",
      "Loss: tensor(0.0282, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 414=====\n",
      "Loss: tensor(0.0281, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 415=====\n",
      "Loss: tensor(0.0279, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 416=====\n",
      "Loss: tensor(0.0278, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 417=====\n",
      "Loss: tensor(0.0277, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 418=====\n",
      "Loss: tensor(0.0276, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 419=====\n",
      "Loss: tensor(0.0274, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 420=====\n",
      "Loss: tensor(0.0273, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 421=====\n",
      "Loss: tensor(0.0272, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 422=====\n",
      "Loss: tensor(0.0271, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 423=====\n",
      "Loss: tensor(0.0269, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 424=====\n",
      "Loss: tensor(0.0268, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 425=====\n",
      "Loss: tensor(0.0267, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 426=====\n",
      "Loss: tensor(0.0266, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 427=====\n",
      "Loss: tensor(0.0265, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 428=====\n",
      "Loss: tensor(0.0263, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 429=====\n",
      "Loss: tensor(0.0262, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 430=====\n",
      "Loss: tensor(0.0261, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 431=====\n",
      "Loss: tensor(0.0260, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 432=====\n",
      "Loss: tensor(0.0259, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 433=====\n",
      "Loss: tensor(0.0258, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 434=====\n",
      "Loss: tensor(0.0257, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 435=====\n",
      "Loss: tensor(0.0255, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 436=====\n",
      "Loss: tensor(0.0254, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 437=====\n",
      "Loss: tensor(0.0253, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 438=====\n",
      "Loss: tensor(0.0252, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 439=====\n",
      "Loss: tensor(0.0251, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 440=====\n",
      "Loss: tensor(0.0250, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 441=====\n",
      "Loss: tensor(0.0249, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 442=====\n",
      "Loss: tensor(0.0248, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 443=====\n",
      "Loss: tensor(0.0247, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 444=====\n",
      "Loss: tensor(0.0246, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 445=====\n",
      "Loss: tensor(0.0245, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 446=====\n",
      "Loss: tensor(0.0244, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 447=====\n",
      "Loss: tensor(0.0243, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 448=====\n",
      "Loss: tensor(0.0242, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 449=====\n",
      "Loss: tensor(0.0241, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 450=====\n",
      "Loss: tensor(0.0240, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 451=====\n",
      "Loss: tensor(0.0239, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 452=====\n",
      "Loss: tensor(0.0238, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 453=====\n",
      "Loss: tensor(0.0237, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 454=====\n",
      "Loss: tensor(0.0236, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 455=====\n",
      "Loss: tensor(0.0235, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 456=====\n",
      "Loss: tensor(0.0234, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 457=====\n",
      "Loss: tensor(0.0233, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 458=====\n",
      "Loss: tensor(0.0232, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 459=====\n",
      "Loss: tensor(0.0231, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 460=====\n",
      "Loss: tensor(0.0230, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 461=====\n",
      "Loss: tensor(0.0229, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 462=====\n",
      "Loss: tensor(0.0228, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 463=====\n",
      "Loss: tensor(0.0227, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 464=====\n",
      "Loss: tensor(0.0226, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 465=====\n",
      "Loss: tensor(0.0226, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 466=====\n",
      "Loss: tensor(0.0225, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 467=====\n",
      "Loss: tensor(0.0224, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 468=====\n",
      "Loss: tensor(0.0223, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 469=====\n",
      "Loss: tensor(0.0222, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 470=====\n",
      "Loss: tensor(0.0221, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 471=====\n",
      "Loss: tensor(0.0220, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 472=====\n",
      "Loss: tensor(0.0219, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 473=====\n",
      "Loss: tensor(0.0219, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 474=====\n",
      "Loss: tensor(0.0218, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 475=====\n",
      "Loss: tensor(0.0217, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 476=====\n",
      "Loss: tensor(0.0216, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 477=====\n",
      "Loss: tensor(0.0215, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 478=====\n",
      "Loss: tensor(0.0214, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 479=====\n",
      "Loss: tensor(0.0214, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 480=====\n",
      "Loss: tensor(0.0213, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 481=====\n",
      "Loss: tensor(0.0212, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 482=====\n",
      "Loss: tensor(0.0211, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 483=====\n",
      "Loss: tensor(0.0210, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 484=====\n",
      "Loss: tensor(0.0210, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 485=====\n",
      "Loss: tensor(0.0209, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 486=====\n",
      "Loss: tensor(0.0208, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 487=====\n",
      "Loss: tensor(0.0207, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 488=====\n",
      "Loss: tensor(0.0207, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 489=====\n",
      "Loss: tensor(0.0206, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 490=====\n",
      "Loss: tensor(0.0205, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 491=====\n",
      "Loss: tensor(0.0204, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 492=====\n",
      "Loss: tensor(0.0203, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 493=====\n",
      "Loss: tensor(0.0203, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 494=====\n",
      "Loss: tensor(0.0202, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 495=====\n",
      "Loss: tensor(0.0201, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 496=====\n",
      "Loss: tensor(0.0201, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 497=====\n",
      "Loss: tensor(0.0200, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 498=====\n",
      "Loss: tensor(0.0199, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n",
      "=====Epoch 499=====\n",
      "Loss: tensor(0.0198, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Accuracy: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD\n",
    "\n",
    "def accuracy(pred, label):\n",
    "  # TODO: Implement the accuracy function. This function takes the \n",
    "  # pred tensor (the resulting tensor after sigmoid) and the label \n",
    "  # tensor (torch.LongTensor). Predicted value greater than 0.5 will \n",
    "  # be classified as label 1. Else it will be classified as label 0.\n",
    "  # The returned accuracy should be rounded to 4 decimal places. \n",
    "  # For example, accuracy 0.82956 will be rounded to 0.8296.\n",
    "\n",
    "  accu = 0.0\n",
    "\n",
    "  ############# Your code here ############\n",
    "  import numpy as np\n",
    "  pred = [1 if item > 0.5 else 0 for item in pred]\n",
    "  num_match = (np.array(pred) == np.array(train_label)).sum()\n",
    "  accu = num_match / len(train_label)\n",
    "  accu = round(accu, 4)\n",
    "  #########################################\n",
    "\n",
    "  return accu\n",
    "\n",
    "def train(emb, loss_fn, sigmoid, train_label, train_edge):\n",
    "  # TODO: Train the embedding layer here. You can also change epochs and \n",
    "  # learning rate. In general, you need to implement: \n",
    "  # (1) Get the embeddings of the nodes in train_edge\n",
    "  # (2) Dot product the embeddings between each node pair\n",
    "  # (3) Feed the dot product result into sigmoid\n",
    "  # (4) Feed the sigmoid output into the loss_fn\n",
    "  # (5) Print both loss and accuracy of each epoch \n",
    "  # (as a sanity check, the loss should decrease during training)\n",
    "\n",
    "  epochs = 500\n",
    "  learning_rate = 0.1\n",
    "\n",
    "  optimizer = SGD(emb.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "  for i in range(epochs):\n",
    "\n",
    "    ############# Your code here ############\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # (1) Get the embeddings of the nodes in train_edge\n",
    "    emb_v = emb(train_edge[0])\n",
    "    emb_u = emb(train_edge[1])\n",
    "    \n",
    "    # (2) Dot product the embeddings between each node pair\n",
    "    similiarity = torch.sum(emb_v * emb_u, dim=-1)\n",
    "\n",
    "    # (3) Feed the dot product result into sigmoid\n",
    "    pred_label = sigmoid(similiarity)\n",
    "    \n",
    "    # (4) Feed the sigmoid output into the loss_fn\n",
    "    loss = loss_fn(pred_label, train_label)\n",
    "    \n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    \n",
    "    # (5) Print both loss and accuracy of each epoch \n",
    "    acc = accuracy(pred_label, train_label) \n",
    "    print(\"=====Epoch \" + str(i) + \"=====\")\n",
    "    print(\"Loss: \" + str(loss))\n",
    "    print(\"Accuracy: \" + str(acc) + \"\\n\")\n",
    "    #########################################\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "# Generate the positive and negative labels\n",
    "pos_label = torch.ones(pos_edge_index.shape[1], )\n",
    "neg_label = torch.zeros(neg_edge_index.shape[1], )\n",
    "\n",
    "# Concat positive and negative labels into one tensor\n",
    "train_label = torch.cat([pos_label, neg_label], dim=0)\n",
    "\n",
    "# Concat positive and negative edges into one tensor\n",
    "# Since the network is very small, we do not split the edges into val/test sets\n",
    "train_edge = torch.cat([pos_edge_index, neg_edge_index], dim=1)\n",
    "\n",
    "train(emb, loss_fn, sigmoid, train_label, train_edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WX2PSXnTDiNi"
   },
   "source": [
    "## Visualize the final node embeddings\n",
    "Visualize your final embedding here! \n",
    "You can visually compare the figure with the previous embedding figure. \n",
    "After training, you should oberserve that the two classes are more evidently separated. \n",
    "This is a great sanitity check for your implementation as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "MtNgl4VhYKow"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAFlCAYAAAD292MqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nn3IA7XQo8gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the final learned embedding\n",
    "visualize_emb(emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTNyrAoSVeq9"
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_E7J_GkVhY_"
   },
   "source": [
    "In order to get credit, you must go submit your answers on Gradescope."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "CS224W - Colab 1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
